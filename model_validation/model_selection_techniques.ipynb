{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Methods\n",
    "\n",
    "This notebooks demonstrates methods for selecting models that perform on the same domain and task.\n",
    "\n",
    "- Wilcoxon signed-rank test\n",
    "- McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = np.concatenate([x_train, x_test])\n",
    "Y_full = np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_1():\n",
    "\n",
    "    model_1 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(8, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model_1.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2():\n",
    "    model_2 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(32, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model_2.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxon Signed-Rank Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_scores = []\n",
    "model_2_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, Fold 0\n",
      "Train on 46666 samples\n",
      "Epoch 1/3\n",
      "46666/46666 [==============================] - 4s 91us/sample - loss: 0.9551 - accuracy: 0.6738\n",
      "Epoch 2/3\n",
      "46666/46666 [==============================] - 4s 83us/sample - loss: 0.7255 - accuracy: 0.7497\n",
      "Epoch 3/3\n",
      "46666/46666 [==============================] - 4s 83us/sample - loss: 0.6790 - accuracy: 0.7690\n",
      "Model 2, Fold 0\n",
      "Train on 46666 samples\n",
      "Epoch 1/3\n",
      "46666/46666 [==============================] - 4s 95us/sample - loss: 0.5097 - accuracy: 0.8471\n",
      "Epoch 2/3\n",
      "46666/46666 [==============================] - 4s 84us/sample - loss: 0.2898 - accuracy: 0.9136\n",
      "Epoch 3/3\n",
      "46666/46666 [==============================] - 4s 81us/sample - loss: 0.2453 - accuracy: 0.9257\n",
      "Model 1, Fold 1\n",
      "Train on 46667 samples\n",
      "Epoch 1/3\n",
      "46667/46667 [==============================] - 4s 90us/sample - loss: 0.9923 - accuracy: 0.6660\n",
      "Epoch 2/3\n",
      "46667/46667 [==============================] - 4s 81us/sample - loss: 0.7239 - accuracy: 0.7560\n",
      "Epoch 3/3\n",
      "46667/46667 [==============================] - 4s 81us/sample - loss: 0.6740 - accuracy: 0.7762\n",
      "Model 2, Fold 1\n",
      "Train on 46667 samples\n",
      "Epoch 1/3\n",
      "46667/46667 [==============================] - 4s 92us/sample - loss: 0.4820 - accuracy: 0.8607\n",
      "Epoch 2/3\n",
      "46667/46667 [==============================] - 4s 89us/sample - loss: 0.2836 - accuracy: 0.9164\n",
      "Epoch 3/3\n",
      "46667/46667 [==============================] - 4s 82us/sample - loss: 0.2381 - accuracy: 0.9291\n",
      "Model 1, Fold 2\n",
      "Train on 46667 samples\n",
      "Epoch 1/3\n",
      "46667/46667 [==============================] - 4s 93us/sample - loss: 1.0620 - accuracy: 0.6472\n",
      "Epoch 2/3\n",
      "46667/46667 [==============================] - 4s 85us/sample - loss: 0.7526 - accuracy: 0.7572\n",
      "Epoch 3/3\n",
      "46667/46667 [==============================] - 4s 85us/sample - loss: 0.6998 - accuracy: 0.7737\n",
      "Model 2, Fold 2\n",
      "Train on 46667 samples\n",
      "Epoch 1/3\n",
      "46667/46667 [==============================] - 4s 90us/sample - loss: 0.5460 - accuracy: 0.8399\n",
      "Epoch 2/3\n",
      "46667/46667 [==============================] - 4s 81us/sample - loss: 0.3206 - accuracy: 0.9050\n",
      "Epoch 3/3\n",
      "46667/46667 [==============================] - 4s 81us/sample - loss: 0.2713 - accuracy: 0.9195\n"
     ]
    }
   ],
   "source": [
    "# Runt 5-fold cross-validation and save accuracy scores\n",
    "\n",
    "n_split=3\n",
    "\n",
    "for fold_index, (train_index,test_index) in enumerate(KFold(n_split).split(X_full)):\n",
    "    x_train, x_test = X_full[train_index], X_full[test_index]\n",
    "    y_train, y_test = Y_full[train_index], Y_full[test_index]\n",
    "    \n",
    "    \n",
    "    model_1 = create_model_1()\n",
    "    model_2 = create_model_2()\n",
    "    \n",
    "    print(f\"Model 1, Fold {fold_index}\")\n",
    "    model_1.fit(x_train, y_train, epochs=3)\n",
    "    print(f\"Model 2, Fold {fold_index}\")\n",
    "    model_2.fit(x_train, y_train, epochs=3)\n",
    "    \n",
    "    model_1_scores.append(model_1.evaluate(x_test,  y_test, verbose=0)[1])\n",
    "    model_2_scores.append(model_2.evaluate(x_test,  y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8986886, 0.8987271, 0.91239876, 0.8991172, 0.89199847, 0.89962715]\n",
      "[0.9589869, 0.9612137, 0.9705139, 0.94424444, 0.94565636, 0.94595635]\n"
     ]
    }
   ],
   "source": [
    "print(model_1_scores)\n",
    "print(model_2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E0514298\\AppData\\Local\\Continuum\\miniconda3\\envs\\py37\\lib\\site-packages\\scipy\\stats\\morestats.py:2863: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# Use wilcoxon to calculate p-value\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "stat, p = wilcoxon(model_1_scores, model_2_scores, zero_method='zsplit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027707849358079864"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-value\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since p-value < 0.05 we can reject the hypothesis that there is no significant difference between both models\n",
    "- Model 2 performs better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar_table, mcnemar\n",
    "mcnemar_p_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1, Fold 0\n",
      "Train on 46666 samples\n",
      "Epoch 1/3\n",
      "46666/46666 [==============================] - 5s 100us/sample - loss: 1.0368 - accuracy: 0.6446\n",
      "Epoch 2/3\n",
      "46666/46666 [==============================] - 4s 80us/sample - loss: 0.7418 - accuracy: 0.7492\n",
      "Epoch 3/3\n",
      "46666/46666 [==============================] - 4s 81us/sample - loss: 0.6869 - accuracy: 0.7703\n",
      "[5 0 4 ... 0 3 1]\n",
      "\n",
      "Model 2, Fold 0\n",
      "Train on 46666 samples\n",
      "Epoch 1/3\n",
      "46666/46666 [==============================] - 4s 90us/sample - loss: 0.5286 - accuracy: 0.8418\n",
      "Epoch 2/3\n",
      "46666/46666 [==============================] - 4s 83us/sample - loss: 0.2934 - accuracy: 0.9116\n",
      "Epoch 3/3\n",
      "46666/46666 [==============================] - 4s 87us/sample - loss: 0.2500 - accuracy: 0.9248\n",
      "p-value: 1.707573476987988e-231\n",
      "\n",
      "Model 1, Fold 1\n",
      "Train on 46667 samples\n",
      "Epoch 1/3\n",
      "46667/46667 [==============================] - 4s 92us/sample - loss: 1.0483 - accuracy: 0.6430\n",
      "Epoch 2/3\n",
      "46667/46667 [==============================] - 4s 85us/sample - loss: 0.7583 - accuracy: 0.7553\n",
      "Epoch 3/3\n",
      "46667/46667 [==============================] - 4s 81us/sample - loss: 0.7102 - accuracy: 0.7740\n",
      "[7 2 8 ... 1 6 3]\n",
      "\n",
      "Model 2, Fold 1\n",
      "Train on 46667 samples\n",
      "Epoch 1/3\n",
      "46667/46667 [==============================] - 4s 95us/sample - loss: 0.4933 - accuracy: 0.8538\n",
      "Epoch 2/3\n",
      "46667/46667 [==============================] - 4s 83us/sample - loss: 0.2835 - accuracy: 0.9164\n",
      "Epoch 3/3\n",
      "46667/46667 [==============================] - 4s 89us/sample - loss: 0.2396 - accuracy: 0.9284\n",
      "p-value: 9.206628758778992e-205\n",
      "\n",
      "Model 1, Fold 2\n",
      "Train on 46667 samples\n",
      "Epoch 1/3\n",
      "46667/46667 [==============================] - 4s 92us/sample - loss: 1.0203 - accuracy: 0.6556\n",
      "Epoch 2/3\n",
      "46667/46667 [==============================] - 4s 80us/sample - loss: 0.7521 - accuracy: 0.7475\n",
      "Epoch 3/3\n",
      "46667/46667 [==============================] - 4s 80us/sample - loss: 0.7056 - accuracy: 0.7626\n",
      "[5 4 6 ... 4 5 6]\n",
      "\n",
      "Model 2, Fold 2\n",
      "Train on 46667 samples\n",
      "Epoch 1/3\n",
      "46667/46667 [==============================] - 4s 90us/sample - loss: 0.5113 - accuracy: 0.8518\n",
      "Epoch 2/3\n",
      "46667/46667 [==============================] - 4s 81us/sample - loss: 0.2985 - accuracy: 0.9108\n",
      "Epoch 3/3\n",
      "46667/46667 [==============================] - 4s 84us/sample - loss: 0.2594 - accuracy: 0.9242\n",
      "p-value: 2.1780472413873312e-222\n"
     ]
    }
   ],
   "source": [
    "# Runt 5-fold cross-validation and save accuracy scores\n",
    "\n",
    "n_split=3\n",
    "\n",
    "for fold_index, (train_index,test_index) in enumerate(KFold(n_split).split(X_full)):\n",
    "    x_train, x_test = X_full[train_index], X_full[test_index]\n",
    "    y_train, y_test = Y_full[train_index], Y_full[test_index]\n",
    "    \n",
    "    \n",
    "    model_1 = create_model_1()\n",
    "    model_2 = create_model_2()\n",
    "    \n",
    "    print(f\"\\nModel 1, Fold {fold_index}\")\n",
    "    model_1.fit(x_train, y_train, epochs=3)\n",
    "    y_predict_1 = model_1.predict_classes(x_test)\n",
    "    print(y_predict_1)\n",
    "    exit(0)\n",
    "    print(f\"\\nModel 2, Fold {fold_index}\")\n",
    "    model_2.fit(x_train, y_train, epochs=3)\n",
    "    y_predict_2 = model_2.predict_classes(x_test)\n",
    "    \n",
    "    # Calculate p value\n",
    "    tb = mcnemar_table(y_target = y_test, \n",
    "                       y_model1 = y_predict_1, \n",
    "                       y_model2 = y_predict_2)\n",
    "    chi2, p = mcnemar(ary=tb, exact=True)\n",
    "    print(f\"p-value: {p}\")\n",
    "    mcnemar_p_values.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.707573476987988e-231, 9.206628758778992e-205, 2.1780472413873312e-222]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcnemar_p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- McNemar p-values are << 0.05 for all folds\n",
    "- Model 2 performs better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
